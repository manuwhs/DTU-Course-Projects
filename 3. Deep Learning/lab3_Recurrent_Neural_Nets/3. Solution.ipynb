{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "%matplotlib inline\n",
    "# %matplotlib nbagg\n",
    "import tensorflow as tf\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "from data_generator_tensorflow import get_batch, print_valid_characters\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.join('.', '..')) \n",
    "import utils \n",
    "\n",
    "import tf_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent Neural Networks\n",
    "> <span style=\"color:gray\">\n",
    "Original [Theano/Lasagne tutorial](https://github.com/DeepLearningDTU/nvidia_deep_learning_summercamp_2016/) by \n",
    "Lars Maaløe ([larsmaaloee](https://github.com/larsmaaloee)),\n",
    "Søren Kaae Sønderby ([skaae](https://github.com/skaae)), and \n",
    "Casper Sønderby ([casperkaae](https://github.com/casperkaae)). \n",
    "Converted to TensorFlow by \n",
    "Alexander R. Johansen ([alrojo](https://github.com/alrojo)), \n",
    "and updated by \n",
    "Toke Faurby ([faur](https://github.com/Faur)).\n",
    "> </span>\n",
    "\n",
    "Recurrent neural networks (RNN) are the natural type of neural network to use for sequential data e.g. time series analysis, translation, speech recognition, biological sequence analysis etc.\n",
    "RNNs works by recursively applying the same operation to an input $x_t$ and its own hidden state from the previous timestep $h_{t-1}$.\n",
    "That is to say that each layer can be described by the function $f$:\n",
    "\n",
    "$$y_t, h_t = f(x_t, h_{t-1})$$\n",
    "\n",
    "where $y_t$ is the output.\n",
    "An RNN can therefore handle input of varying length.\n",
    "\n",
    "Drawing all the connections in a RNN (left) quickly becomes messy, therefore it is common to use the time unrolled view (right) when representing RNNs.\n",
    "<img src='images/rnn_basic.png', width=600>\n",
    "*Image by [Alex Graves](https://www.cs.toronto.edu/~graves/preprint.pdf)*\n",
    "\n",
    "\n",
    "\n",
    "#### External resources\n",
    "* The code describing RNNs can be tricky to understand at first. \n",
    "R2T2 has a great tutorial series ([part 1](https://r2rt.com/recurrent-neural-networks-in-tensorflow-i.html), [part 2](https://r2rt.com/recurrent-neural-networks-in-tensorflow-ii.html)) that digs into the details of how RNNs are implemented in TensorFlow. This introduction is heavily inspired by part 1.\n",
    "* For more in depth background material on RNNs please see [Supervised Sequence Labelling with Recurrent\n",
    "Neural Networks](https://www.cs.toronto.edu/~graves/preprint.pdf) by Alex Graves\n",
    "* Lastly there is an [official TensorFlow tutorial](https://www.tensorflow.org/tutorials/recurrent) that is also worth a look"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoder-Decoder Models\n",
    "\n",
    "\n",
    "Recurrent networks can be used for several kinds of prediction tasks including: \n",
    "* **One-to-one** - NOT a recurrent network. E.g. image classification.\n",
    "* **One-to-many** - E.g. creating an [image caption](http://cs.stanford.edu/people/karpathy/deepimagesent/) with an RNN.\n",
    "* **Many-to-one** - E.g. sentiment analysis of text.\n",
    "* **Many-to-many** (different lengths) This is a combination of the *one-to-many* and *many-to-One*, and is called an **encoder-decoder** RNN. E.g. machine translation.\n",
    "* **Many-to-many** (same length) Each input has an output. E.g. robotics control.\n",
    "\n",
    "\n",
    "<img src=\"images/types.jpeg\", width=800>\n",
    "\n",
    "*Image courtesy Andrej Karpathy's [blog](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder-Decoder\n",
    "In this exercise we'll implement a Encoder-Decoder RNN based for a simple sequence to sequence translation task.\n",
    "We will use a special kind of unit, called the GRU unit.\n",
    "The GRU unit stores a hidden value per neuron that helps it '*remember*' long-term dependencies.\n",
    "Another popular choice of unit type is LSTM, which store two values, but these are approximately twice as slow as GRU.\n",
    "GRUs (and LSTMs) can be difficult to understand at first.\n",
    "For a very good not-to-mathematical introduction see \n",
    "[Chris Olahs blog](http://colah.github.io/posts/2015-08-Understanding-LSTMs/) or\n",
    "[Andrej Karpathys blog](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)\n",
    "(All their posts are nice and cover various topics within machine-learning).\n",
    "This type of models have shown impressive performance in Neural Machine Translation and Image Caption generation. \n",
    "\n",
    "\n",
    "In the encoder-decoder structure one RNN (blue) encodes the input into a hidden representation, and a second RNN (red) uses this representation to predict the target values.\n",
    "An essential step is deciding how the encoder and decoder should communicate.\n",
    "In the simplest approach you use the last hidden state of the encoder to initialize the decoder.\n",
    "This is what we will do in this notebook, as shown here:\n",
    "\n",
    "<img src='images/enc-dec.png', width=400>\n",
    "\n",
    "#### Teacher forcing\n",
    "We will also use what is called *teacher forcing*.\n",
    "This is shown as the gray lines in the figure.\n",
    "This means that the RNN will implement a sequence of conditional distributions so the $t$th output of the decoder gives $p(y_t|y_1,\\dots,y_{t-1} ,x)$. This formulation will make the task easier and faster for the network to learn because it during training always have access to the correct preceding outputs.\n",
    "A test time where we we don't know the output sequence we have to predict one step at a time. \n",
    "There is no guarantee that we will find the mostly likely decoded *sequence*. A technique called [beam search](https://arxiv.org/pdf/1702.01806.pdf) is used in machine translation and related tasks to look for list of candidate decoded sequences.    \n",
    "\n",
    "\n",
    "\n",
    "#### Alternatives\n",
    "There are other ways to let the encoder and decoder communicate with each other.\n",
    "For instance you can give the last state of the Encoder as input to the Decoder at each decode time step, not just the previously predicted word.\n",
    "Another approache is called **attention**, which lets the Decoder attend to different parts of the encoded input at different timesteps in the decoding process. \n",
    "Attention is shown in the next notebook. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Data\n",
    "Since RNN models can be very slow to train on real large datasets we will generate some simpler training data for this exercise. The task for the RNN is simply to translate a string of letters spelling the numbers between 0-9 into the corresponding numbers i.e\n",
    "\n",
    "    \"one two five\" --> \"125#\"\n",
    "\n",
    "`#` is a special end-of-sequence character, indicating the sequence is done.\n",
    "\n",
    "To input the strings into the RNN model we translate the characters into a vector integers using a simple translation table (i.e. 'h'->16, 'o'-> 17 etc).\n",
    "The code below prints a few input/output pairs using the *get_batch* function which randomy produces the data.\n",
    "\n",
    "\n",
    "In the data loader below will setup the data and print some information. \n",
    "Key to understand are:\n",
    " * ENCODED INPUTS (`inputs`) are feed into the encoder (`A B C D` in the figure)\n",
    " * ENCODED TARGETS OUTPUT (`targets_out`) are what we want the network to predict. This is used to compute the error. (`X Y Z EOS` in the figure) \n",
    " * ENCODED TARGETS INPUT (`targets_in`) are used for teacher forcing during training. (`EOS X Y Z` in the figure) \n",
    " \n",
    "Note; that we use the same symbol for end-of-sequence as for start-of-sequence (`#`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# At the bottom of the script there is some code which saves the model.\n",
    "# If you wish to restore your model from a previous state use this function.\n",
    "load_model = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input types: int32 int32 int32 int32 int32\n",
      "Number of valid characters: 27\n",
      "'0'=0,\t'1'=1,\t'2'=2,\t'3'=3,\t'4'=4,\t'5'=5,\t'6'=6,\t'7'=7,\t'8'=8,\t'9'=9,\t'#'=10,\t'u'=11,\t's'=12,\t'x'=13,\t'z'=14,\t'w'=15,\t'h'=16,\t'g'=17,\t'i'=18,\t'f'=19,\t'e'=20,\t'r'=21,\t' '=22,\t'v'=23,\t'n'=24,\t'o'=25,\t't'=26,\t\n",
      "Stop/start character = #\n",
      "\n",
      "SAMPLE 0\n",
      "TEXT INPUTS:\t\t\t two six six\n",
      "ENCODED INPUTS:\t\t\t [26 15 25 22 12 18 13 22 12 18 13  0  0]\n",
      "INPUTS SEQUENCE LENGTH:\t\t 11\n",
      "TEXT TARGETS OUTPUT:\t\t 266#\n",
      "TEXT TARGETS INPUT:\t\t #266\n",
      "ENCODED TARGETS OUTPUT:\t\t [ 2  6  6 10]\n",
      "ENCODED TARGETS INPUT:\t\t [10  2  6  6]\n",
      "TARGETS SEQUENCE LENGTH:\t 4\n",
      "TARGETS MASK:\t\t\t [ 1.  1.  1.  1.]\n",
      "\n",
      "SAMPLE 1\n",
      "TEXT INPUTS:\t\t\t one seven one\n",
      "ENCODED INPUTS:\t\t\t [25 24 20 22 12 20 23 20 24 22 25 24 20]\n",
      "INPUTS SEQUENCE LENGTH:\t\t 13\n",
      "TEXT TARGETS OUTPUT:\t\t 171#\n",
      "TEXT TARGETS INPUT:\t\t #171\n",
      "ENCODED TARGETS OUTPUT:\t\t [ 1  7  1 10]\n",
      "ENCODED TARGETS INPUT:\t\t [10  1  7  1]\n",
      "TARGETS SEQUENCE LENGTH:\t 4\n",
      "TARGETS MASK:\t\t\t [ 1.  1.  1.  1.]\n",
      "\n",
      "SAMPLE 2\n",
      "TEXT INPUTS:\t\t\t five nine\n",
      "ENCODED INPUTS:\t\t\t [19 18 23 20 22 24 18 24 20  0  0  0  0]\n",
      "INPUTS SEQUENCE LENGTH:\t\t 9\n",
      "TEXT TARGETS OUTPUT:\t\t 59#\n",
      "TEXT TARGETS INPUT:\t\t #59\n",
      "ENCODED TARGETS OUTPUT:\t\t [ 5  9 10  0]\n",
      "ENCODED TARGETS INPUT:\t\t [10  5  9  0]\n",
      "TARGETS SEQUENCE LENGTH:\t 3\n",
      "TARGETS MASK:\t\t\t [ 1.  1.  1.  0.]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 3\n",
    "inputs, inputs_seqlen, targets_in, targets_out, targets_seqlen, targets_mask, \\\n",
    "text_inputs, text_targets_in, text_targets_out = \\\n",
    "    get_batch(batch_size=batch_size, max_digits=4, min_digits=2)\n",
    "\n",
    "print(\"input types:\", inputs.dtype, inputs_seqlen.dtype, targets_in.dtype, targets_out.dtype, targets_seqlen.dtype)\n",
    "print_valid_characters()\n",
    "print(\"Stop/start character = #\")\n",
    "\n",
    "for i in range(batch_size):\n",
    "    print(\"\\nSAMPLE\",i)\n",
    "    print(\"TEXT INPUTS:\\t\\t\\t\", text_inputs[i])\n",
    "    print(\"ENCODED INPUTS:\\t\\t\\t\", inputs[i])\n",
    "    print(\"INPUTS SEQUENCE LENGTH:\\t\\t\", inputs_seqlen[i])\n",
    "    print(\"TEXT TARGETS OUTPUT:\\t\\t\", text_targets_out[i])\n",
    "    print(\"TEXT TARGETS INPUT:\\t\\t\", text_targets_in[i])\n",
    "    print(\"ENCODED TARGETS OUTPUT:\\t\\t\", targets_out[i])\n",
    "    print(\"ENCODED TARGETS INPUT:\\t\\t\", targets_in[i])\n",
    "    print(\"TARGETS SEQUENCE LENGTH:\\t\", targets_seqlen[i])\n",
    "    print(\"TARGETS MASK:\\t\\t\\t\", targets_mask[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder-Decoder model setup\n",
    "Below is the TensorFlow model definition. We use an embedding layer to go from integer representation to vector representation of the input.\n",
    "\n",
    "TensorFlow has implementations of LSTM and GRU units.\n",
    "Both implementations assume that the input from the tensor below has the shape **`[batch_size, max_time, input_size]`**, (unless you have `time_major=True`, in which case it is `[max_time, batch_size, input_size]`).\n",
    "\n",
    "Note that we have made use of a custom decoder wrapper which can be found in `tf_utils.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# resetting the graph\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Setting up hyperparameters and general configs\n",
    "MAX_DIGITS = 10\n",
    "MIN_DIGITS = 5\n",
    "NUM_INPUTS = 27\n",
    "NUM_OUTPUTS = 11 #(0-9 + '#')\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "# try various learning rates 1e-2 to 1e-5\n",
    "LEARNING_RATE = 0.005\n",
    "X_EMBEDDINGS = 8\n",
    "t_EMBEDDINGS = 8\n",
    "NUM_UNITS_ENC = 16\n",
    "NUM_UNITS_DEC = 16\n",
    "\n",
    "\n",
    "# Setting up placeholders, these are the tensors that we \"feed\" to our network\n",
    "Xs = tf.placeholder(tf.int32, shape=[None, None], name='X_input')\n",
    "ts_in = tf.placeholder(tf.int32, shape=[None, None], name='t_input_in')\n",
    "ts_out = tf.placeholder(tf.int32, shape=[None, None], name='t_input_out')\n",
    "X_len = tf.placeholder(tf.int32, shape=[None], name='X_len')\n",
    "t_len = tf.placeholder(tf.int32, shape=[None], name='X_len')\n",
    "t_mask = tf.placeholder(tf.float32, shape=[None, None], name='t_mask')\n",
    "\n",
    "\n",
    "### Building the model\n",
    "# first we build the embeddings to make our characters into dense, trainable vectors\n",
    "X_embeddings = tf.get_variable('X_embeddings', [NUM_INPUTS, X_EMBEDDINGS],\n",
    "                               initializer=tf.random_normal_initializer(stddev=0.1))\n",
    "t_embeddings = tf.get_variable('t_embeddings', [NUM_OUTPUTS, t_EMBEDDINGS],\n",
    "                               initializer=tf.random_normal_initializer(stddev=0.1))\n",
    "\n",
    "X_embedded = tf.gather(X_embeddings, Xs, name='embed_X')\n",
    "t_embedded = tf.gather(t_embeddings, ts_in, name='embed_t')\n",
    "\n",
    "\n",
    "## forward encoding\n",
    "enc_cell = tf.nn.rnn_cell.GRUCell(NUM_UNITS_ENC)\n",
    "_, enc_state = tf.nn.dynamic_rnn(cell=enc_cell, inputs=X_embedded,\n",
    "                                 sequence_length=X_len, dtype=tf.float32)\n",
    "# use below incase TF's makes issues\n",
    "# enc_state, _ = tf_utils.encoder(X_embedded, X_len, 'encoder', NUM_UNITS_ENC)\n",
    "#\n",
    "# enc_state = tf.concat(1, [enc_state, enc_state])\n",
    "\n",
    "## decoding\n",
    "# note that we are using a wrapper for decoding here, this wrapper is hardcoded to only use GRU\n",
    "# check out tf_utils to see how you make your own decoder\n",
    "\n",
    "# setting up weights for computing the final output\n",
    "W_out = tf.get_variable('W_out', [NUM_UNITS_DEC, NUM_OUTPUTS])\n",
    "b_out = tf.get_variable('b_out', [NUM_OUTPUTS])\n",
    "\n",
    "dec_out, valid_dec_out = tf_utils.decoder(enc_state, t_embedded, t_len, \n",
    "                                          NUM_UNITS_DEC, t_embeddings,\n",
    "                                          W_out, b_out)\n",
    "\n",
    "## reshaping to have [batch_size*seqlen, num_units]\n",
    "out_tensor = tf.reshape(dec_out, [-1, NUM_UNITS_DEC])\n",
    "valid_out_tensor = tf.reshape(valid_dec_out, [-1, NUM_UNITS_DEC])\n",
    "# computing output\n",
    "out_tensor = tf.matmul(out_tensor, W_out) + b_out\n",
    "valid_out_tensor = tf.matmul(valid_out_tensor, W_out) + b_out\n",
    "\n",
    "## reshaping back to sequence\n",
    "# print('X_len', tf.shape(X_len)[0])\n",
    "b_size = tf.shape(X_len)[0] # use a variable we know has batch_size in [0]\n",
    "seq_len = tf.shape(t_embedded)[1] # variable we know has sequence length in [1]\n",
    "num_out = tf.constant(NUM_OUTPUTS) # casting NUM_OUTPUTS to a tensor variable\n",
    "out_shape = tf.concat([tf.expand_dims(b_size, 0),\n",
    "                      tf.expand_dims(seq_len, 0),\n",
    "                      tf.expand_dims(num_out, 0)],\n",
    "                     axis=0)\n",
    "\n",
    "out_tensor = tf.reshape(out_tensor, out_shape)\n",
    "valid_out_tensor = tf.reshape(valid_out_tensor, out_shape)\n",
    "# handling shape loss\n",
    "#out_tensor.set_shape([None, None, NUM_OUTPUTS])\n",
    "y = out_tensor\n",
    "y_valid = valid_out_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_embeddings:0                           (27, 8)\n",
      "t_embeddings:0                           (11, 8)\n",
      "rnn/gru_cell/gates/kernel:0              (24, 32)\n",
      "rnn/gru_cell/gates/bias:0                (32,)\n",
      "rnn/gru_cell/candidate/kernel:0          (24, 16)\n",
      "rnn/gru_cell/candidate/bias:0            (16,)\n",
      "W_out:0                                  (16, 11)\n",
      "b_out:0                                  (11,)\n",
      "decoder/W_z_x:0                          (8, 16)\n",
      "decoder/W_z_h:0                          (16, 16)\n",
      "decoder/b_z:0                            (16,)\n",
      "decoder/W_r_x:0                          (8, 16)\n",
      "decoder/W_r_h:0                          (16, 16)\n",
      "decoder/b_r:0                            (16,)\n",
      "decoder/W_c_x:0                          (8, 16)\n",
      "decoder/W_c_h:0                          (16, 16)\n",
      "decoder/b_h:0                            (16,)\n"
     ]
    }
   ],
   "source": [
    "# print all the variable names and shapes\n",
    "for var in tf.global_variables ():\n",
    "    s = var.name + \" \"*(40-len(var.name))\n",
    "    print(s, var.value().get_shape())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the cost function, gradient clipping and accuracy\n",
    "Because the targets are categorical we use the cross entropy error.\n",
    "As the data is sequential we use the sequence to sequence cross entropy supplied in `tf_utils.py`.\n",
    "We use the Adam optimizer but you can experiment with the different optimizers implemented in [TensorFlow](https://www.tensorflow.org/api_docs/python/tf/train/Optimizer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loss_and_acc(preds):\n",
    "    # sequence_loss_tensor is a modification of TensorFlow's own sequence_to_sequence_loss\n",
    "    # TensorFlow's seq2seq loss works with a 2D list instead of a 3D tensors\n",
    "    loss = tf_utils.sequence_loss_tensor(preds, ts_out, t_mask, NUM_OUTPUTS) # notice that we use ts_out here!\n",
    "\n",
    "    ## if you want regularization\n",
    "    #reg_scale = 0.00001\n",
    "    #regularize = tf.contrib.layers.l2_regularizer(reg_scale)\n",
    "    #params = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES)\n",
    "    #reg_term = sum([regularize(param) for param in params])\n",
    "    #loss += reg_term\n",
    "    \n",
    "    ## calculate accuracy\n",
    "    argmax = tf.to_int32(tf.argmax(preds, 2))\n",
    "    correct = tf.to_float(tf.equal(argmax, ts_out)) * t_mask\n",
    "    accuracy = tf.reduce_sum(correct) / tf.reduce_sum(t_mask)\n",
    "    return loss, accuracy, argmax\n",
    "\n",
    "loss, accuracy, predictions = loss_and_acc(y)\n",
    "loss_valid, accuracy_valid, predictions_valid = loss_and_acc(y_valid)\n",
    "\n",
    "# use lobal step to keep track of our iterations\n",
    "global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "\n",
    "# pick optimizer, try momentum or adadelta\n",
    "optimizer = tf.train.AdamOptimizer(LEARNING_RATE)\n",
    "\n",
    "# extract gradients for each variable\n",
    "grads_and_vars = optimizer.compute_gradients(loss)\n",
    "\n",
    "## add below for clipping by norm\n",
    "# gradients, variables = zip(*grads_and_vars)  # unzip list of tuples\n",
    "# clipped_gradients, global_norm = (\n",
    "#    tf.clip_by_global_norm(gradients, self.clip_norm) )\n",
    "# grads_and_vars = zip(clipped_gradients, variables)\n",
    "# apply gradients and make trainable function\n",
    "train_op = optimizer.apply_gradients(grads_and_vars, global_step=global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-8-3a13120a4a03>:3: all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Please use tf.global_variables instead.\n",
      "X_embeddings:0                           (27, 8)\n",
      "t_embeddings:0                           (11, 8)\n",
      "rnn/gru_cell/gates/kernel:0              (24, 32)\n",
      "rnn/gru_cell/gates/bias:0                (32,)\n",
      "rnn/gru_cell/candidate/kernel:0          (24, 16)\n",
      "rnn/gru_cell/candidate/bias:0            (16,)\n",
      "W_out:0                                  (16, 11)\n",
      "b_out:0                                  (11,)\n",
      "decoder/W_z_x:0                          (8, 16)\n",
      "decoder/W_z_h:0                          (16, 16)\n",
      "decoder/b_z:0                            (16,)\n",
      "decoder/W_r_x:0                          (8, 16)\n",
      "decoder/W_r_h:0                          (16, 16)\n",
      "decoder/b_r:0                            (16,)\n",
      "decoder/W_c_x:0                          (8, 16)\n",
      "decoder/W_c_h:0                          (16, 16)\n",
      "decoder/b_h:0                            (16,)\n",
      "global_step:0                            ()\n",
      "beta1_power:0                            ()\n",
      "beta2_power:0                            ()\n",
      "X_embeddings/Adam:0                      (27, 8)\n",
      "X_embeddings/Adam_1:0                    (27, 8)\n",
      "t_embeddings/Adam:0                      (11, 8)\n",
      "t_embeddings/Adam_1:0                    (11, 8)\n",
      "rnn/gru_cell/gates/kernel/Adam:0         (24, 32)\n",
      "rnn/gru_cell/gates/kernel/Adam_1:0       (24, 32)\n",
      "rnn/gru_cell/gates/bias/Adam:0           (32,)\n",
      "rnn/gru_cell/gates/bias/Adam_1:0         (32,)\n",
      "rnn/gru_cell/candidate/kernel/Adam:0     (24, 16)\n",
      "rnn/gru_cell/candidate/kernel/Adam_1:0   (24, 16)\n",
      "rnn/gru_cell/candidate/bias/Adam:0       (16,)\n",
      "rnn/gru_cell/candidate/bias/Adam_1:0     (16,)\n",
      "W_out/Adam:0                             (16, 11)\n",
      "W_out/Adam_1:0                           (16, 11)\n",
      "b_out/Adam:0                             (11,)\n",
      "b_out/Adam_1:0                           (11,)\n",
      "decoder/W_z_x/Adam:0                     (8, 16)\n",
      "decoder/W_z_x/Adam_1:0                   (8, 16)\n",
      "decoder/W_z_h/Adam:0                     (16, 16)\n",
      "decoder/W_z_h/Adam_1:0                   (16, 16)\n",
      "decoder/b_z/Adam:0                       (16,)\n",
      "decoder/b_z/Adam_1:0                     (16,)\n",
      "decoder/W_r_x/Adam:0                     (8, 16)\n",
      "decoder/W_r_x/Adam_1:0                   (8, 16)\n",
      "decoder/W_r_h/Adam:0                     (16, 16)\n",
      "decoder/W_r_h/Adam_1:0                   (16, 16)\n",
      "decoder/b_r/Adam:0                       (16,)\n",
      "decoder/b_r/Adam_1:0                     (16,)\n",
      "decoder/W_c_x/Adam:0                     (8, 16)\n",
      "decoder/W_c_x/Adam_1:0                   (8, 16)\n",
      "decoder/W_c_h/Adam:0                     (16, 16)\n",
      "decoder/W_c_h/Adam_1:0                   (16, 16)\n",
      "decoder/b_h/Adam:0                       (16,)\n",
      "decoder/b_h/Adam_1:0                     (16,)\n"
     ]
    }
   ],
   "source": [
    "# print all the variable names and shapes\n",
    "# notice that we now have the optimizer Adam as well!\n",
    "for var in tf.all_variables():\n",
    "    s = var.name + \" \"*(40-len(var.name))\n",
    "    print(s, var.value().get_shape())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Start the session\n",
    "# restricting memory usage, TensorFlow is greedy and will use all memory otherwise\n",
    "gpu_opts = tf.GPUOptions(per_process_gpu_memory_fraction=0.35)\n",
    "sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_opts))\n",
    "\n",
    "# Initialize parameters\n",
    "if load_model:\n",
    "    try:\n",
    "        tf.train.Saver().restore(sess, \"/save/model.ckpt\")\n",
    "    except:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        print('Model not found, new parameters initialized')\n",
    "else:\n",
    "    sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SAMPLE 0\n",
      "TEXT INPUTS:\t\t\t two six six\n",
      "TEXT TARGETS INPUT:\t\t #266\n",
      "\n",
      "SAMPLE 1\n",
      "TEXT INPUTS:\t\t\t one seven one\n",
      "TEXT TARGETS INPUT:\t\t #171\n",
      "\n",
      "SAMPLE 2\n",
      "TEXT INPUTS:\t\t\t five nine\n",
      "TEXT TARGETS INPUT:\t\t #59\n",
      "y (3, 4, 11)\n",
      "y_valid (3, 4, 11)\n"
     ]
    }
   ],
   "source": [
    "# as always, test the forward pass and initialize the tf.Session!\n",
    "for i in range(batch_size):\n",
    "    print(\"\\nSAMPLE\",i)\n",
    "    print(\"TEXT INPUTS:\\t\\t\\t\", text_inputs[i])\n",
    "    print(\"TEXT TARGETS INPUT:\\t\\t\", text_targets_in[i])\n",
    "\n",
    "feed_dict = {Xs: inputs, X_len: inputs_seqlen, ts_in: targets_in,\n",
    "             ts_out: targets_out, t_len: targets_seqlen}\n",
    "\n",
    "# test training forwardpass\n",
    "fetches = [y]\n",
    "res = sess.run(fetches=fetches, feed_dict=feed_dict)\n",
    "print(\"y\", res[0].shape)\n",
    "\n",
    "# test validation forwardpass\n",
    "fetches = [y_valid]\n",
    "res = sess.run(fetches=fetches, feed_dict=feed_dict)\n",
    "print(\"y_valid\", res[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_val (5000, 56)\n",
      "t_out_val (5000, 11)\n"
     ]
    }
   ],
   "source": [
    "#Generate some validation data\n",
    "X_val, X_len_val, t_in_val, t_out_val, t_len_val, t_mask_val, \\\n",
    "text_inputs_val, text_targets_in_val, text_targets_out_val = \\\n",
    "    get_batch(batch_size=5000, max_digits=MAX_DIGITS, min_digits=MIN_DIGITS)\n",
    "print(\"X_val\", X_val.shape)\n",
    "print(\"t_out_val\", t_out_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "Training RNN can take a while, especially if you are running it on your laptop.\n",
    "We won't train the model to completion, as the trends we are interested in can be seen earlier.\n",
    "If training takes to long feel free to stop it even earlier by interrupting the kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "CPU times: user 11min 5s, sys: 2min 2s, total: 13min 7s\n",
      "Wall time: 3min 18s\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAEPCAYAAACDTflkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4c91ea5ef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "## If you get an error, remove this line! It makes the error message hard to understand.\n",
    "\n",
    "# setting up running parameters\n",
    "val_interval = 5000\n",
    "samples_to_process = 2e5\n",
    "samples_processed = 0\n",
    "samples_val = []\n",
    "costs, accs_val = [], []\n",
    "plt.figure()\n",
    "try:\n",
    "    while samples_processed < samples_to_process:\n",
    "        # load data\n",
    "        X_tr, X_len_tr, t_in_tr, t_out_tr, t_len_tr, t_mask_tr, \\\n",
    "        text_inputs_tr, text_targets_in_tr, text_targets_out_tr = \\\n",
    "            get_batch(batch_size=BATCH_SIZE,max_digits=MAX_DIGITS,min_digits=MIN_DIGITS)\n",
    "        # make fetches\n",
    "        fetches_tr = [train_op, loss, accuracy]\n",
    "        # set up feed dict\n",
    "        feed_dict_tr = {Xs: X_tr, X_len: X_len_tr, ts_in: t_in_tr,\n",
    "             ts_out: t_out_tr, t_len: t_len_tr, t_mask: t_mask_tr}\n",
    "        # run the model\n",
    "        res = tuple(sess.run(fetches=fetches_tr, feed_dict=feed_dict_tr))\n",
    "        _, batch_cost, batch_acc = res\n",
    "        costs += [batch_cost]\n",
    "        samples_processed += BATCH_SIZE\n",
    "        #if samples_processed % 1000 == 0: print(batch_cost, batch_acc)\n",
    "        #validation data\n",
    "        if samples_processed % val_interval == 0:\n",
    "            #print(\"validating\")\n",
    "            fetches_val = [accuracy_valid, y_valid]\n",
    "            feed_dict_val = {Xs: X_val, X_len: X_len_val, ts_in: t_in_val,\n",
    "             ts_out: t_out_val, t_len: t_len_val, t_mask: t_mask_val}\n",
    "            res = tuple(sess.run(fetches=fetches_val, feed_dict=feed_dict_val))\n",
    "            acc_val, output_val = res\n",
    "            samples_val += [samples_processed]\n",
    "            accs_val += [acc_val]\n",
    "            plt.plot(samples_val, accs_val, 'g-')\n",
    "            plt.ylabel('Validation Accuracy', fontsize=15)\n",
    "            plt.xlabel('Processed samples', fontsize=15)\n",
    "            plt.title('', fontsize=20)\n",
    "            plt.grid('on')\n",
    "            plt.savefig(\"out.png\")\n",
    "            display.display(display.Image(filename=\"out.png\"))\n",
    "            display.clear_output(wait=True)\n",
    "except KeyboardInterrupt:\n",
    "    pass\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcIAAAGyCAYAAAB3OsSEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4c809a4ef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot of validation accuracy for each target position\n",
    "plt.figure(figsize=(7,7))\n",
    "masked_output_val = np.ma.array(np.argmax(output_val,axis=2)==t_out_val, mask=1-t_mask_val)\n",
    "plt.plot(np.ma.mean(masked_output_val, axis=0))\n",
    "plt.ylabel('Accuracy', fontsize=15)\n",
    "plt.xlabel('Target position', fontsize=15)\n",
    "#plt.title('', fontsize=20)\n",
    "plt.grid('on')\n",
    "plt.show()\n",
    "#why do the plot look like this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in file: /tmp/model.ckpt\n"
     ]
    }
   ],
   "source": [
    "## Save model\n",
    "# Read more about saving and loading models at https://www.tensorflow.org/programmers_guide/saved_model\n",
    "\n",
    "# Save model\n",
    "save_path = tf.train.Saver().save(sess, \"/tmp/model.ckpt\")\n",
    "print(\"Model saved in file: %s\" % save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Close the session, and free the resources\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1)\n",
    "1. What is the final validation performance? \n",
    "\n",
    "1. Why do you think it is not better?\n",
    "\n",
    "1. Comment on the accuracy for each position in of the output symbols?\n",
    "\n",
    "___\n",
    "Answer:\n",
    "2. What is the final validation performance? \n",
    "\n",
    "The final accuracy is around 60%. When we see it distributed in the positions, we see that the initial and final positions have the highest accuracy.\n",
    "\n",
    "2. Why do you think it is not better?\n",
    "\n",
    "The 2 main reasons why it is not better is first because the training has not converged, it can be seen that the trend indicates that the accuracy of the system can improve if trained further. Also, due to the teacher forcing, if we have a mistake in the early decoded numbers, it propagates to the prediction of the rest of the numbers of the sequence.\n",
    "\n",
    "Also, this might not be the best scheme to use since the prediciton of one of the output digits is actually independent of the surrounding ones. In a perfect scheme, the surrounding names should not give info. In this case, we have a scheme in which the hidden representation will somehow encode the output numbers to output and their position, thus giving the previous number can give information on what is the next number to output. It is as if that \"teaching number\" that we give as input is an \"index\" of the actual number to output, using the hidden state.\n",
    "\n",
    "2. Comment on the accuracy for each position in of the output symbols?\n",
    "\n",
    "As we can see, at the beggining we have a big accuracy, the network does well predicting the first sample, but not perfect. For this sample, the input symbol is # so the network has correctly learn to output the first number when that input is given. For the few next predictions the accuracy decreases, since the error of the first number is propagated, as we can see, the accuracy decreases linearly. Then the latest positions have an increased accuracy.\n",
    "\n",
    "The 11-th position has accuracy almost 100%, since it will always be # whenever the chain has 10 digits. The minimum number of digits to predict is 5 and maximum is 10. When we have less than 10, the last position is also #. We later use a mask so that the other characters do not count towards accuracy. So the position from 6 to 10 will sometimes have the # character, and sometimes they will have a number, the bigger the position, the bigger the probability of # instead of a number, so the entropy of the position decreases, then its classification is easier and therefore the accuracy increases.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2)\n",
    "The model has two GRU networks. The ```GRUEncoder``` and the ```GRUDecoder```.\n",
    "A GRU is parameterized by a update gate $u$, a  reset gate $r$, the cell $c$, and the hidden state $h$:\n",
    "\n",
    "![](images/GRUeq.png)\n",
    "*Equations as described in the [Lasagne GRU documentation](http://lasagne.readthedocs.io/en/latest/modules/layers/recurrent.html#lasagne.layers.GRULayer).*\n",
    "\n",
    "**Note** that the notation in the implementation (`tf_utils.py`) $z$ is used instead of $u$.\n",
    "\n",
    "Under normal circumstances, such as in the TensorFlow GRUCell implementation, these gates have been stacked for faster computation, but in the custom decoder each weight and bias are as described in the original [article for GRU](https://arxiv.org/abs/1406.1078).\n",
    " 1. Try to explain the shape of $W_{xr}$ and $W_{hr}$.\n",
    " 1. Why are they different? \n",
    "\n",
    "___\n",
    "Answer:\n",
    "\n",
    "$W_{xr}$ corresponds to the input weights of the hidden neurons that connect with the original input. The shape of $W_{xr}$ is given by the size of the input and the size of the hidden state, in this case the number of hidden nerons: 16. The dimensionality of the input is 8 because we transformed the 27-one-hot sparse representation into a 8-dimensional representation with a neural network.\n",
    "\n",
    "$W_{hr}$ corresponds to the input weights of the hidden neurons that connect with the previous state. The shape of $W_{hr}$ is given by the size of the previous hidden state and the number of hidden neurons of the network. In this case 16. The dimensionality of the state does not change with time and is equal to the number of hidden neurons 16.\n",
    "\n",
    "They are different because they connect data with different dimensionality to the hidden neurons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3)\n",
    "The GRU-unit is able to ignore the input and just copy the previous hidden state.\n",
    "In the beginning of training this might be desireable behaviour because it helps the model learn long range dependencies.\n",
    "You can make the model ignore the input by modifying initial bias values.\n",
    "1. What bias would you modify and how would you modify it?\n",
    "\n",
    "Again you'll need to refer to the [GRU equations](http://lasagne.readthedocs.io/en/latest/modules/layers/recurrent.html#lasagne.layers.GRULayer)\n",
    "Further, if you look into `tf_utils.py` and search for the `decoder(...)` function, you will see that the init for each weight and bias can be changed.\n",
    "\n",
    "___\n",
    "Answer:\n",
    "\n",
    "The most straight forward way to ignore the input is just forcing the system to output the previous state $h_{t-1}$. Looking at the equations below:\n",
    "\n",
    "![](images/GRUeq.png)\n",
    "\n",
    "% We can see that this happens when $u_t = 0$. we can force this in the equation by making $b_u$ very negatively big. This way no matter the value of $x_t$ and $h_{t-1}$ (as long as it is not hugely possitive), then  $h_t = h_{t-1}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4)\n",
    "In the example we stack a softmax layer on top of a Recurrent layer. In the code snippet below explain how we can do that?\n",
    "___\n",
    "Answer: \n",
    "\n",
    "So, starting from the beggining we have 16 chain batches where every chain has 140 characters encoded with a one-hot 40-dimensional represenation. In the Forward Pass, each of these 16x140 characters generates the 10-length hidden state. Since the softmax layer only accepts 2D representations, what we do is using reshape, concatenating all of those 10-dimensional hidden states. Where 10 correspond to each of the dimensions of the hidden state and then 2240 is the concatenation of every value that it had for each of the 140 samples per 16 chains. Then the output layer has 11 dimensions, so the output per each state possible hidden state has dimension 11, that is the dimension of l_softmax_. And after that, we rearrange the predicted values (11-d) of each hidden state, which correponds to each sample, back to the original distribution where we know to which sample belongs each 11-d output. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l_input_\t (16, 140, 40)\n",
      "l_gru_\t\t (16, 140, 10)\n",
      "l_reshape_\t (2240, 10)\n",
      "l_softmax_\t (2240, 11)\n",
      "l_softmax_seq_\t (16, 140, 11)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "bs_, seqlen_, numinputs_ = 16, 140, 40 # Batch_size, Sequence_length, number_of_inputs\n",
    "x_pl_ = tf.placeholder(tf.float32, [bs_, seqlen_, numinputs_])\n",
    "gru_cell_ = tf.nn.rnn_cell.GRUCell(10)\n",
    "l_gru_, gru_state_ = tf.nn.dynamic_rnn(gru_cell_, x_pl_, dtype=tf.float32)\n",
    "l_reshape_ = tf.reshape(l_gru_, [-1, 10])\n",
    "\n",
    "l_softmax_ = tf.contrib.layers.fully_connected(l_reshape_, 11, activation_fn=tf.nn.softmax)\n",
    "l_softmax_seq_ = tf.reshape(l_softmax_, [bs_, seqlen_, -1])\n",
    "\n",
    "print(\"l_input_\\t\", x_pl_.get_shape())\n",
    "print(\"l_gru_\\t\\t\", l_gru_.get_shape())\n",
    "print(\"l_reshape_\\t\", l_reshape_.get_shape())\n",
    "print(\"l_softmax_\\t\", l_softmax_.get_shape())\n",
    "print(\"l_softmax_seq_\\t\", l_softmax_seq_.get_shape())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional Exercise 1)\n",
    "Why do you think the validation performance looks more \"jig-saw\" like compared to FFN and CNN models?\n",
    "\n",
    "___\n",
    "Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional Exercise 2)\n",
    "You are interested in doing sentiment analysis on tweets, i.e classification as positive or negative. You decide read over the twitter seqeuence and use the last hidden state to do the classification. How can you modify the small network above to only output a single classification for network? Hints: look at the gru\\_state\\_ or the [tf.slice](https://www.tensorflow.org/versions/r0.10/api_docs/python/array_ops.html#slice) in the API.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional Exercise 3)\n",
    "Bidirectional Encoders are usually implemented by running a forward model and  a backward model (a forward model on a reversed sequence) separately and the concatenating them before parsing them on to the next layer. To reverse the sequence try looking at [tf.reverse_sequence](https://www.tensorflow.org/versions/r0.10/api_docs/python/array_ops.html#reverse_sequence)\n",
    "\n",
    "Implement a Bidirectional encoder model.\n",
    "Here is some code to get you started:\n",
    "\n",
    "``` python\n",
    "enc_cell = tf.nn.rnn_cell.GRUCell(NUM_UNITS_ENC)\n",
    "_, enc_state = tf.nn.dynamic_rnn(cell=enc_cell, inputs=X_embedded,\n",
    "                                 sequence_length=X_len, dtype=tf.float32, scope=\"rnn_forward\")\n",
    "X_embedded_backwards = tf.reverse_sequence(X_embedded, tf.to_int64(X_len), 1)\n",
    "enc_cell_backwards = tf.nn.rnn_cell.GRUCell(NUM_UNITS_ENC)\n",
    "_, enc_state_backwards = tf.nn.dynamic_rnn(cell=enc_cell_backwards, inputs=X_embedded_backwards,\n",
    "                                 sequence_length=X_len, dtype=tf.float32, scope=\"rnn_backward\")\n",
    "\n",
    "enc_state = tf.concat(1, [enc_state, enc_state_backwards])\n",
    "```\n",
    "\n",
    "Note: you will need to double the NUM_UNITS_DEC, as it currently does not support different sizes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Book's Exercise\n",
    "\n",
    "This exercise belongs to chapter 3 in the book\n",
    "\n",
    "As discussed above, one way of expanding the MNIST training data is to use small rotations of training images. What's a problem that might occur if we allow arbitrarily large rotations of training images?\n",
    "\n",
    "### Answer\n",
    "\n",
    "This small rotations could help the network be rotation invariant, being able to detect numbers that are rotated to some degree, this follows the human intuition that a number slightly rotated is fundamentally the same number. The problem is that in our number representation, the number 6 is equal to the number 9 rotates 180 degrees. It can be confusing as well to classify some numbers if they are too much rotated. So we should contraint the number of degrees of the rotation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
